"use strict";
/*
 * ATTENTION: An "eval-source-map" devtool has been used.
 * This devtool is neither made for production nor for readable output files.
 * It uses "eval()" calls to create a separate source file with attached SourceMaps in the browser devtools.
 * If you are trying to read the output file, select a different devtool (https://webpack.js.org/configuration/devtool/)
 * or disable the default devtool with "devtool: false".
 * If you are looking for production-ready output files, see mode: "production" (https://webpack.js.org/configuration/mode/).
 */
self["webpackHotUpdate_N_E"]("app/page",{

/***/ "(app-pages-browser)/./src/data/skills.json":
/*!******************************!*\
  !*** ./src/data/skills.json ***!
  \******************************/
/***/ (function(module, __unused_webpack_exports, __webpack_require__) {

module.exports = /*#__PURE__*/JSON.parse('[{"name":"Python","level":5,"content":"I am proficient in Python and have used it extensively for backend development, data analysis, and machine learning projects. I am familiar with libraries like NumPy, Pandas, Matplotlib, and Scikit-learn."},{"name":"Java","level":5,"content":"I have strong Java skills and have worked on projects using Java."},{"name":"C++","level":4,"content":"I have intermediate-level skills in C++ and have used it for implementing algorithms, data structures."},{"name":"JavaScript","level":4,"content":"I am proficient in JavaScript and have used it for frontend development, web applications, and server-side scripting."},{"name":"Docker","level":4,"content":"I have experience with Docker and have used it for containerizing my applications, managing dependencies, and simplifying deployment processes."},{"name":"Kubernetes","level":4,"content":"I have experience with Kubernetes and have used it for orchestrating containerized applications, managing clusters, and scaling applications."},{"name":"Machine Learning","level":5,"content":"I have a strong understanding of machine learning concepts and have implemented various algorithms for classification, regression, clustering, and reinforcement learning. I am familiar with libraries like TensorFlow, PyTorch, and Scikit-learn."},{"name":"NLP","level":5,"content":"I have experience with natural language processing and have worked on projects involving text classification, sentiment analysis, named entity recognition, and text generation. I am familiar with libraries like NLTK, spaCy, and Gensim."},{"name":"Web Development (HTML5, CSS3, Django)","level":5,"content":"I am proficient in web development, having worked extensively with HTML5, CSS3, and Django. I have built responsive websites and web applications, using HTML5 APIs like Canvas, WebSockets, and Web Workers, as well as CSS3 features such as Flexbox and Grid. Additionally, I have experience with Django for building full-stack web applications with a strong focus on back-end functionality."},{"name":"SQL (Oracle)","level":4,"content":"I have experience with SQL and have used PostgreSQL for managing relational databases, writing complex queries, and optimizing database performance."},{"name":"NumPy","level":5,"content":"I am proficient in NumPy, a fundamental package for scientific computing with Python. I have used NumPy for array manipulation, linear algebra, and mathematical operations."},{"name":"Pandas","level":5,"content":"I am proficient in Pandas, a fast, powerful, and flexible open-source data analysis and manipulation tool. I have used Pandas for data cleaning, data exploration, and data analysis."},{"name":"Bash","level":4,"content":"I have used Bash to write shell scripts for automation, system administration, and data processing."},{"name":"Apache Spark","level":4,"content":"I have experience with Apache Spark, a powerful distributed computing framework. I have used it for processing large datasets, performing ETL tasks, and implementing machine learning pipelines using its MLlib library."},{"name":"Apache Airflow","level":4,"content":"I have experience with Apache Airflow, a platform to programmatically author, schedule, and monitor workflows. I have used it to orchestrate ETL pipelines, manage task dependencies, and automate data workflows efficiently."},{"name":"ETL Processes","level":5,"content":"I am skilled in designing and optimizing ETL pipelines to extract, transform, and load large datasets into data warehouses or lakes. I have experience with tools like Apache NiFi, Apache Airflow, and Talend."},{"name":"Cloud Platforms (AWS/GCP/Azure)","level":5,"content":"I have experience with cloud platforms like AWS, GCP, and Azure, and have used them for data storage, processing, and deploying scalable data solutions."},{"name":"Data Warehousing (Snowflake, Redshift)","level":5,"content":"I am proficient in designing and managing data warehouses using tools like Snowflake and AWS Redshift, ensuring high-performance queries and efficient data storage."},{"name":"Data Lake Architecture","level":5,"content":"I have experience in building and managing data lakes, enabling efficient storage and analysis of large-scale unstructured data using AWS S3, Azure Data Lake, and Hadoop."},{"name":"Big Data Technologies (Hadoop, Spark, Kafka)","level":4,"content":"I am familiar with big data technologies like Hadoop, Spark, and Kafka, which I have used to process and stream large datasets efficiently."},{"name":"NoSQL Databases (MongoDB, Cassandra)","level":4,"content":"I have worked with NoSQL databases like MongoDB and Cassandra for handling large volumes of unstructured data in real-time applications."},{"name":"Data Modeling","level":5,"content":"I have experience with data modeling, ensuring that data structures align with business needs and optimizing them for performance in both relational and non-relational databases."},{"name":"Data Quality & Governance","level":5,"content":"I am experienced in implementing data quality and governance measures, ensuring data integrity, accuracy, and compliance with relevant standards and policies."}]');

/***/ })

});